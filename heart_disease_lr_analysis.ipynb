{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Risk Prediction: Logistic Regression\n",
    "\n",
    "**Course:** AREP - Machine Learning Bootcamp\n",
    "\n",
    "**Objective:** Implement logistic regression from scratch to predict heart disease risk.\n",
    "\n",
    "**Dataset:** Heart_Disease_Prediction.csv from Kaggle (270 patients, 14 features)\n",
    "\n",
    "**Constraints:** NumPy, Pandas, Matplotlib only. No scikit-learn for core training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages \n",
    "%pip install numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "np.random.seed(42)  # so i can have the same results later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 1: Load and Prepare the Dataset\n",
    "\n",
    "## 1.1 Load the Data\n",
    "\n",
    "Dataset downloaded from: https://www.kaggle.com/datasets/neurocipher/heartdisease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Heart_Disease_Prediction.csv')\n",
    "\n",
    "print(f\"Loaded: Heart_Disease_Prediction.csv\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column Information:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0] if missing.sum() > 0 else \"No missing values in the set\")\n",
    "print(f\"\\nTotal missing: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Heart Disease'\n",
    "\n",
    "print(f\"Target column: '{target_col}'\")\n",
    "print(f\"\\nTarget value counts:\")\n",
    "print(df[target_col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize Target Variable\n",
    "\n",
    "Ensure target is binary: 1 = disease presence, 0 = absence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique values in target: {df[target_col].unique()}\")\n",
    "\n",
    "# Binarize: 'Presence' = 1, 'Absence' = 0\n",
    "df['target_binary'] = df[target_col].apply(lambda x: 1 if x == 'Presence' else 0)\n",
    "\n",
    "print(f\"\\nBinarized target distribution:\")\n",
    "print(df['target_binary'].value_counts())\n",
    "print(f\"\\nDisease rate: {df['target_binary'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Bar plot\n",
    "class_counts = df['target_binary'].value_counts()\n",
    "axes[0].bar(['No Disease (0)', 'Disease (1)'], class_counts.values, \n",
    "            color=['green', 'red'], edgecolor='black')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Class Distribution')\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    axes[0].text(i, v + 2, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(class_counts.values, labels=['No Disease', 'Disease'], \n",
    "            autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'],\n",
    "            explode=(0, 0.05), startangle=90)\n",
    "axes[1].set_title('Class Proportion')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we see which are features (exclude target), so they must be numeric\n",
    "exclude_cols = [target_col, 'target_binary']\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "numerical_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Available features ({len(feature_cols)}):\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of key numerical features\n",
    "key_features = numerical_cols[:6] if len(numerical_cols) >= 6 else numerical_cols\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(key_features):\n",
    "    if idx < len(axes):\n",
    "        # Histograma\n",
    "        for label, color in [(0, 'green'), (1, 'red')]:\n",
    "            subset = df[df['target_binary'] == label][col]\n",
    "            axes[idx].hist(subset, bins=20, alpha=0.5, color=color, \n",
    "                          label=f\"{'Disease' if label else 'No Disease'}\")\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].set_title(f'Distribution of {col}')\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(len(key_features), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Outliers (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers using IQR method\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower) | (data[column] > upper)]\n",
    "    return len(outliers), lower, upper\n",
    "\n",
    "print(\"Outlier Analysis (IQR method):\")\n",
    "print(\"-\" * 50)\n",
    "for col in numerical_cols[:8]:\n",
    "    count, lower, upper = detect_outliers_iqr(df, col)\n",
    "    if count > 0:\n",
    "        print(f\"{col}: {count} outliers (range: {lower:.1f} - {upper:.1f})\")\n",
    "\n",
    "print(\"\\nNote: Outliers are kept as they may represent genuine clinical variations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Feature Selection\n",
    "\n",
    "Select at least 6 features for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for the model (using actual column names from dataset)\n",
    "selected_features = [\n",
    "    'Age',\n",
    "    'Sex', \n",
    "    'Chest pain type',\n",
    "    'BP',\n",
    "    'Cholesterol',\n",
    "    'FBS over 120',\n",
    "    'EKG results',\n",
    "    'Max HR',\n",
    "    'Exercise angina',\n",
    "    'ST depression'\n",
    "]\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features for the model:\")\n",
    "for i, f in enumerate(selected_features, 1):\n",
    "    print(f\"  {i}. {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Train/Test Split (70/30 Stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(X, y, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform stratified train/test split without sklearn.\n",
    "    Maintains class proportions in both sets.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Get indices for each class\n",
    "    idx_class_0 = np.where(y == 0)[0]\n",
    "    idx_class_1 = np.where(y == 1)[0]\n",
    "    \n",
    "    # Shuffle indices\n",
    "    np.random.shuffle(idx_class_0)\n",
    "    np.random.shuffle(idx_class_1)\n",
    "    \n",
    "    # Calculate split sizes\n",
    "    n_test_0 = int(len(idx_class_0) * test_size)\n",
    "    n_test_1 = int(len(idx_class_1) * test_size)\n",
    "    \n",
    "    # Split each class\n",
    "    test_idx = np.concatenate([idx_class_0[:n_test_0], idx_class_1[:n_test_1]])\n",
    "    train_idx = np.concatenate([idx_class_0[n_test_0:], idx_class_1[n_test_1:]])\n",
    "    \n",
    "    # Shuffle final indices\n",
    "    np.random.shuffle(test_idx)\n",
    "    np.random.shuffle(train_idx)\n",
    "    \n",
    "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "# Prepare data\n",
    "X = df[selected_features].values\n",
    "y = df['target_binary'].values\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = stratified_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(f\"  Class 0: {np.sum(y_train == 0)} ({np.mean(y_train == 0)*100:.1f}%)\")\n",
    "print(f\"  Class 1: {np.sum(y_train == 1)} ({np.mean(y_train == 1)*100:.1f}%)\")\n",
    "print(f\"\\nClass distribution in test set:\")\n",
    "print(f\"  Class 0: {np.sum(y_test == 0)} ({np.mean(y_test == 0)*100:.1f}%)\")\n",
    "print(f\"  Class 1: {np.sum(y_test == 1)} ({np.mean(y_test == 1)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Feature Normalization (Standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardize features using training set statistics.\n",
    "    z = (x - mean) / std\n",
    "    \"\"\"\n",
    "    # Compute mean and std from training set only\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    std[std == 0] = 1\n",
    "    \n",
    "    # Normalize both sets using training statistics\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_test_norm = (X_test - mean) / std\n",
    "    \n",
    "    return X_train_norm, X_test_norm, mean, std\n",
    "\n",
    "# Normalize\n",
    "X_train_norm, X_test_norm, feature_mean, feature_std = normalize_features(X_train, X_test)\n",
    "\n",
    "print(\"Feature Statistics (Training Set):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Feature':<20} {'Mean':>10} {'Std':>10} {'Norm Mean':>12} {'Norm Std':>10}\")\n",
    "print(\"-\" * 60)\n",
    "for i, feat in enumerate(selected_features):\n",
    "    print(f\"{feat:<20} {feature_mean[i]:>10.2f} {feature_std[i]:>10.2f} \"\n",
    "          f\"{X_train_norm[:, i].mean():>12.4f} {X_train_norm[:, i].std():>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Data Preparation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DATA PREPARATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nDataset: Heart Disease from Kaggle\")\n",
    "print(f\"Source: https://www.kaggle.com/datasets/neurocipher/heartdisease\")\n",
    "print(f\"\\nTotal samples: {len(df)}\")\n",
    "print(f\"Disease presence rate: {df['target_binary'].mean()*100:.1f}%\")\n",
    "print(f\"\\nFeatures selected ({len(selected_features)}): {selected_features}\")\n",
    "print(f\"\\nTrain/Test split: 70/30 (stratified)\")\n",
    "print(f\"  - Training: {len(X_train)} samples\")\n",
    "print(f\"  - Test: {len(X_test)} samples\")\n",
    "print(f\"\\nPreprocessing: Standardization (z-score normalization)\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2: Implement Basic Logistic Regression\n",
    "\n",
    "## 2.1 Mathematical Foundation\n",
    "\n",
    "### Sigmoid Function\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "### Hypothesis\n",
    "$$h_\\theta(x) = \\sigma(\\theta^T x) = \\frac{1}{1 + e^{-\\theta^T x}}$$\n",
    "\n",
    "### Binary Cross-Entropy Cost Function\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1-y^{(i)}) \\log(1-h_\\theta(x^{(i)})) \\right]$$\n",
    "\n",
    "### Gradient\n",
    "$$\\frac{\\partial J}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Core Functions Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute sigmoid function.\n",
    "    Clips input to avoid overflow.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    z : array-like\n",
    "        Input values\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    array-like\n",
    "        Sigmoid of z, values in range (0, 1)\n",
    "    \"\"\"\n",
    "    # Clip to prevent overflow\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Test sigmoid\n",
    "test_z = np.array([-10, -1, 0, 1, 10])\n",
    "print(\"Sigmoid function test:\")\n",
    "print(f\"z = {test_z}\")\n",
    "print(f\"sigmoid(z) = {sigmoid(test_z)}\")\n",
    "print(f\"\\nNote: sigmoid(0) = 0.5 (as expected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sigmoid\n",
    "z_range = np.linspace(-10, 10, 100)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(z_range, sigmoid(z_range), 'b-', linewidth=2)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='Threshold (0.5)')\n",
    "plt.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('sigmoid(z)')\n",
    "plt.title('Sigmoid Function')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Compute binary cross-entropy cost function.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : ndarray (m, n)\n",
    "        Training examples\n",
    "    y : ndarray (m,)\n",
    "        Target labels (0 or 1)\n",
    "    w : ndarray (n,)\n",
    "        Weight parameters\n",
    "    b : float\n",
    "        Bias parameter\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Cost value\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # Compute predictions\n",
    "    z = X @ w + b\n",
    "    h = sigmoid(z)\n",
    "    \n",
    "    # Clip to avoid log(0)\n",
    "    epsilon = 1e-15\n",
    "    h = np.clip(h, epsilon, 1 - epsilon)\n",
    "    \n",
    "    # Binary cross-entropy\n",
    "    cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    \n",
    "    return cost\n",
    "\n",
    "# Test cost function\n",
    "n_features = X_train_norm.shape[1]\n",
    "w_test = np.zeros(n_features)\n",
    "b_test = 0.0\n",
    "initial_cost = compute_cost(X_train_norm, y_train, w_test, b_test)\n",
    "print(f\"Initial cost (w=0, b=0): {initial_cost:.4f}\")\n",
    "print(f\"Expected initial cost for balanced data: ~{np.log(2):.4f} (log(2))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(X, y, w, b):\n",
    "    \"\"\"\n",
    "    Compute gradients for logistic regression.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : ndarray (m, n)\n",
    "        Training examples\n",
    "    y : ndarray (m,)\n",
    "        Target labels\n",
    "    w : ndarray (n,)\n",
    "        Weight parameters\n",
    "    b : float\n",
    "        Bias parameter\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dw : ndarray (n,)\n",
    "        Gradient of cost w.r.t. w\n",
    "    db : float\n",
    "        Gradient of cost w.r.t. b\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # Compute predictions\n",
    "    z = X @ w + b\n",
    "    h = sigmoid(z)\n",
    "    \n",
    "    # Compute error\n",
    "    error = h - y\n",
    "    \n",
    "    # Compute gradients\n",
    "    dw = (1/m) * (X.T @ error)\n",
    "    db = (1/m) * np.sum(error)\n",
    "    \n",
    "    return dw, db\n",
    "\n",
    "# Test gradients\n",
    "dw, db = compute_gradients(X_train_norm, y_train, w_test, b_test)\n",
    "print(f\"Initial gradients:\")\n",
    "print(f\"dw = {dw}\")\n",
    "print(f\"db = {db:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Gradient Descent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_init, b_init, alpha, num_iterations, verbose=True):\n",
    "    \"\"\"\n",
    "    Perform gradient descent for logistic regression.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : ndarray (m, n)\n",
    "        Training examples\n",
    "    y : ndarray (m,)\n",
    "        Target labels\n",
    "    w_init : ndarray (n,)\n",
    "        Initial weights\n",
    "    b_init : float\n",
    "        Initial bias\n",
    "    alpha : float\n",
    "        Learning rate\n",
    "    num_iterations : int\n",
    "        Number of iterations\n",
    "    verbose : bool\n",
    "        Print progress\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w : ndarray (n,)\n",
    "        Learned weights\n",
    "    b : float\n",
    "        Learned bias\n",
    "    cost_history : list\n",
    "        Cost at each iteration\n",
    "    \"\"\"\n",
    "    w = w_init.copy()\n",
    "    b = b_init\n",
    "    cost_history = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Compute gradients\n",
    "        dw, db = compute_gradients(X, y, w, b)\n",
    "        \n",
    "        # Update parameters\n",
    "        w = w - alpha * dw\n",
    "        b = b - alpha * db\n",
    "        \n",
    "        # Track cost\n",
    "        cost = compute_cost(X, y, w, b)\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        # Print progress\n",
    "        if verbose and i % 200 == 0:\n",
    "            print(f\"Iteration {i:5d}: cost = {cost:.6f}\")\n",
    "    \n",
    "    return w, b, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "alpha = 0.1  # Learning rate\n",
    "num_iterations = 2000\n",
    "\n",
    "# Initialize parameters\n",
    "n_features = X_train_norm.shape[1]\n",
    "w_init = np.zeros(n_features)\n",
    "b_init = 0.0\n",
    "\n",
    "print(\"Training Logistic Regression Model\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Learning rate (alpha): {alpha}\")\n",
    "print(f\"Iterations: {num_iterations}\")\n",
    "print(f\"Features: {n_features}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Train\n",
    "w_learned, b_learned, cost_history = gradient_descent(\n",
    "    X_train_norm, y_train, w_init, b_init, alpha, num_iterations\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(f\"Final cost: {cost_history[-1]:.6f}\")\n",
    "print(f\"Cost reduction: {((cost_history[0] - cost_history[-1]) / cost_history[0] * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display learned parameters\n",
    "print(\"\\nLearned Parameters:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'Feature':<20} {'Weight':>12}\")\n",
    "print(\"-\" * 40)\n",
    "for feat, weight in zip(selected_features, w_learned):\n",
    "    print(f\"{feat:<20} {weight:>12.4f}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'Bias (b)':<20} {b_learned:>12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Cost vs Iterations Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cost vs iterations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Full plot\n",
    "axes[0].plot(cost_history, 'b-', linewidth=1)\n",
    "axes[0].set_xlabel('Iteration')\n",
    "axes[0].set_ylabel('Cost (Binary Cross-Entropy)')\n",
    "axes[0].set_title('Cost vs Iterations')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Log scale\n",
    "axes[1].semilogy(cost_history, 'b-', linewidth=1)\n",
    "axes[1].set_xlabel('Iteration')\n",
    "axes[1].set_ylabel('Cost (log scale)')\n",
    "axes[1].set_title('Cost vs Iterations (Log Scale)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCONVERGENCE ANALYSIS:\")\n",
    "print(f\"- Initial cost: {cost_history[0]:.4f}\")\n",
    "print(f\"- Final cost: {cost_history[-1]:.4f}\")\n",
    "print(f\"- The model converges smoothly without oscillations.\")\n",
    "print(f\"- Most improvement occurs in the first ~500 iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Make predictions using trained logistic regression model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : ndarray (m, n)\n",
    "        Input features\n",
    "    w : ndarray (n,)\n",
    "        Weights\n",
    "    b : float\n",
    "        Bias\n",
    "    threshold : float\n",
    "        Classification threshold (default 0.5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    predictions : ndarray (m,)\n",
    "        Binary predictions (0 or 1)\n",
    "    probabilities : ndarray (m,)\n",
    "        Probability estimates\n",
    "    \"\"\"\n",
    "    z = X @ w + b\n",
    "    probabilities = sigmoid(z)\n",
    "    predictions = (probabilities >= threshold).astype(int)\n",
    "    return predictions, probabilities\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred, y_train_prob = predict(X_train_norm, w_learned, b_learned)\n",
    "y_test_pred, y_test_prob = predict(X_test_norm, w_learned, b_learned)\n",
    "\n",
    "print(\"Sample predictions (first 10 test samples):\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Actual':<10} {'Predicted':<12} {'Probability':>12}\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(10):\n",
    "    print(f\"{y_test[i]:<10} {y_test_pred[i]:<12} {y_test_prob[i]:>12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute classification metrics without sklearn.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with: accuracy, precision, recall, f1_score, confusion_matrix\n",
    "    \"\"\"\n",
    "    # Confusion matrix components\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': np.array([[TN, FP], [FN, TP]])\n",
    "    }\n",
    "\n",
    "# Compute metrics for train and test\n",
    "train_metrics = compute_metrics(y_train, y_train_pred)\n",
    "test_metrics = compute_metrics(y_test, y_test_pred)\n",
    "\n",
    "print(\"CLASSIFICATION METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{'Metric':<15} {'Training Set':>15} {'Test Set':>15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Accuracy':<15} {train_metrics['accuracy']*100:>14.2f}% {test_metrics['accuracy']*100:>14.2f}%\")\n",
    "print(f\"{'Precision':<15} {train_metrics['precision']*100:>14.2f}% {test_metrics['precision']*100:>14.2f}%\")\n",
    "print(f\"{'Recall':<15} {train_metrics['recall']*100:>14.2f}% {test_metrics['recall']*100:>14.2f}%\")\n",
    "print(f\"{'F1-Score':<15} {train_metrics['f1_score']*100:>14.2f}% {test_metrics['f1_score']*100:>14.2f}%\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for idx, (metrics, title) in enumerate([(train_metrics, 'Training Set'), \n",
    "                                         (test_metrics, 'Test Set')]):\n",
    "    cm = metrics['confusion_matrix']\n",
    "    im = axes[idx].imshow(cm, cmap='Blues')\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            axes[idx].text(j, i, str(cm[i, j]), ha='center', va='center', \n",
    "                          fontsize=20, fontweight='bold')\n",
    "    \n",
    "    axes[idx].set_xticks([0, 1])\n",
    "    axes[idx].set_yticks([0, 1])\n",
    "    axes[idx].set_xticklabels(['Predicted 0', 'Predicted 1'])\n",
    "    axes[idx].set_yticklabels(['Actual 0', 'Actual 1'])\n",
    "    axes[idx].set_title(f'Confusion Matrix - {title}\\nAccuracy: {metrics[\"accuracy\"]*100:.1f}%')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance based on weight magnitude\n",
    "importance = np.abs(w_learned)\n",
    "sorted_idx = np.argsort(importance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['red' if w_learned[i] > 0 else 'blue' for i in sorted_idx]\n",
    "plt.barh(range(len(selected_features)), importance[sorted_idx], color=colors)\n",
    "plt.yticks(range(len(selected_features)), [selected_features[i] for i in sorted_idx])\n",
    "plt.xlabel('Absolute Weight')\n",
    "plt.title('Feature Importance (by Weight Magnitude)\\nRed: Increases risk, Blue: Decreases risk')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFEATURE INTERPRETATION:\")\n",
    "print(\"-\" * 60)\n",
    "for i in sorted_idx:\n",
    "    direction = \"INCREASES\" if w_learned[i] > 0 else \"DECREASES\"\n",
    "    print(f\"{selected_features[i]:<20}: w={w_learned[i]:>8.4f} -> {direction} disease risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Step 2 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 2 SUMMARY: LOGISTIC REGRESSION IMPLEMENTATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel: Logistic Regression (Binary Classification)\")\n",
    "print(f\"\\nTraining Parameters:\")\n",
    "print(f\"  - Learning rate (alpha): {alpha}\")\n",
    "print(f\"  - Iterations: {num_iterations}\")\n",
    "print(f\"  - Features: {n_features}\")\n",
    "print(f\"\\nConvergence:\")\n",
    "print(f\"  - Initial cost: {cost_history[0]:.4f}\")\n",
    "print(f\"  - Final cost: {cost_history[-1]:.4f}\")\n",
    "print(f\"  - Cost reduction: {((cost_history[0] - cost_history[-1]) / cost_history[0] * 100):.1f}%\")\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  Training Accuracy: {train_metrics['accuracy']*100:.2f}%\")\n",
    "print(f\"  Test Accuracy: {test_metrics['accuracy']*100:.2f}%\")\n",
    "print(f\"  Test Precision: {test_metrics['precision']*100:.2f}%\")\n",
    "print(f\"  Test Recall: {test_metrics['recall']*100:.2f}%\")\n",
    "print(f\"  Test F1-Score: {test_metrics['f1_score']*100:.2f}%\")\n",
    "print(f\"\\nKey Observations:\")\n",
    "print(f\"  - Model converged smoothly without oscillations.\")\n",
    "print(f\"  - Similar train/test accuracy suggests good generalization.\")\n",
    "print(f\"  - Top predictive features identified from weight analysis.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 3: Visualize Decision Boundaries\n",
    "\n",
    "Select 3 feature pairs and visualize the decision boundary for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_2d_model(X_2d, y, alpha=0.1, num_iterations=2000):\n",
    "    \"\"\"Train logistic regression on 2 features.\"\"\"\n",
    "    mean = X_2d.mean(axis=0)\n",
    "    std = X_2d.std(axis=0)\n",
    "    std[std == 0] = 1\n",
    "    X_norm = (X_2d - mean) / std\n",
    "    \n",
    "    w = np.zeros(2)\n",
    "    b = 0.0\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        h = sigmoid(X_norm @ w + b)\n",
    "        error = h - y\n",
    "        w = w - alpha * (1/len(y)) * (X_norm.T @ error)\n",
    "        b = b - alpha * (1/len(y)) * np.sum(error)\n",
    "    \n",
    "    return w, b, mean, std\n",
    "\n",
    "def plot_decision_boundary(X_2d, y, w, b, mean, std, feature_names, ax):\n",
    "    \"\"\"Plot data points and decision boundary.\"\"\"\n",
    "    X_norm = (X_2d - mean) / std\n",
    "    \n",
    "    # Create mesh grid\n",
    "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    \n",
    "    # Normalize grid points\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    grid_norm = (grid - mean) / std\n",
    "    \n",
    "    # Predict\n",
    "    Z = sigmoid(grid_norm @ w + b)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    ax.contourf(xx, yy, Z, levels=[0, 0.5, 1], alpha=0.3, colors=['lightgreen', 'lightcoral'])\n",
    "    ax.contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n",
    "    \n",
    "    # Scatter points\n",
    "    ax.scatter(X_2d[y==0, 0], X_2d[y==0, 1], c='green', edgecolors='black', label='No Disease', s=50)\n",
    "    ax.scatter(X_2d[y==1, 0], X_2d[y==1, 1], c='red', edgecolors='black', label='Disease', s=50)\n",
    "    \n",
    "    ax.set_xlabel(feature_names[0])\n",
    "    ax.set_ylabel(feature_names[1])\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature pairs to visualize\n",
    "feature_pairs = [\n",
    "    ('Age', 'Cholesterol'),\n",
    "    ('BP', 'Max HR'),\n",
    "    ('ST depression', 'Chest pain type')\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for idx, (f1, f2) in enumerate(feature_pairs):\n",
    "    i1 = selected_features.index(f1)\n",
    "    i2 = selected_features.index(f2)\n",
    "    X_2d = X_train[:, [i1, i2]]\n",
    "    \n",
    "    w, b, mean, std = train_2d_model(X_2d, y_train)\n",
    "    plot_decision_boundary(X_2d, y_train, w, b, mean, std, [f1, f2], axes[idx])\n",
    "    \n",
    "    # Calculate 2D accuracy\n",
    "    X_2d_norm = (X_2d - mean) / std\n",
    "    preds = (sigmoid(X_2d_norm @ w + b) >= 0.5).astype(int)\n",
    "    acc = np.mean(preds == y_train) * 100\n",
    "    axes[idx].set_title(f'{f1} vs {f2}\\nAccuracy: {acc:.1f}%')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDECISION BOUNDARY ANALYSIS:\")\n",
    "print(\"- The black line represents the decision boundary (P = 0.5).\")\n",
    "print(\"- Green region: model predicts No Disease.\")\n",
    "print(\"- Red region: model predicts Disease.\")\n",
    "print(\"- Classes overlap significantly, reflecting the challenge of this classification task.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 4: Regularization (L2)\n",
    "\n",
    "L2 regularization adds a penalty term to prevent overfitting:\n",
    "\n",
    "$$J_{reg}(\\theta) = J(\\theta) + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} w_j^2$$\n",
    "\n",
    "The gradient becomes:\n",
    "$$\\frac{\\partial J_{reg}}{\\partial w_j} = \\frac{\\partial J}{\\partial w_j} + \\frac{\\lambda}{m} w_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_reg(X, y, w, b, lambda_):\n",
    "    \"\"\"Compute cost with L2 regularization.\"\"\"\n",
    "    m = X.shape[0]\n",
    "    z = X @ w + b\n",
    "    h = sigmoid(z)\n",
    "    epsilon = 1e-15\n",
    "    h = np.clip(h, epsilon, 1 - epsilon)\n",
    "    \n",
    "    cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    reg_term = (lambda_ / (2 * m)) * np.sum(w ** 2)\n",
    "    return cost + reg_term\n",
    "\n",
    "def compute_gradients_reg(X, y, w, b, lambda_):\n",
    "    \"\"\"Compute gradients with L2 regularization.\"\"\"\n",
    "    m = X.shape[0]\n",
    "    z = X @ w + b\n",
    "    h = sigmoid(z)\n",
    "    error = h - y\n",
    "    \n",
    "    dw = (1/m) * (X.T @ error) + (lambda_ / m) * w\n",
    "    db = (1/m) * np.sum(error)\n",
    "    return dw, db\n",
    "\n",
    "def gradient_descent_reg(X, y, w_init, b_init, alpha, num_iterations, lambda_):\n",
    "    \"\"\"Gradient descent with L2 regularization.\"\"\"\n",
    "    w = w_init.copy()\n",
    "    b = b_init\n",
    "    cost_history = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        dw, db = compute_gradients_reg(X, y, w, b, lambda_)\n",
    "        w = w - alpha * dw\n",
    "        b = b - alpha * db\n",
    "        cost = compute_cost_reg(X, y, w, b, lambda_)\n",
    "        cost_history.append(cost)\n",
    "    \n",
    "    return w, b, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different lambda values\n",
    "lambdas = [0, 0.01, 0.1, 1, 10]\n",
    "results = []\n",
    "\n",
    "print(\"Testing different regularization strengths (lambda):\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for lambda_ in lambdas:\n",
    "    w_reg, b_reg, _ = gradient_descent_reg(\n",
    "        X_train_norm, y_train, np.zeros(n_features), 0.0, \n",
    "        alpha=0.1, num_iterations=2000, lambda_=lambda_\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred_reg, _ = predict(X_train_norm, w_reg, b_reg)\n",
    "    y_test_pred_reg, _ = predict(X_test_norm, w_reg, b_reg)\n",
    "    \n",
    "    # Metrics\n",
    "    train_acc = np.mean(y_train_pred_reg == y_train) * 100\n",
    "    test_acc = np.mean(y_test_pred_reg == y_test) * 100\n",
    "    weight_norm = np.sqrt(np.sum(w_reg ** 2))\n",
    "    \n",
    "    results.append({\n",
    "        'lambda': lambda_,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'weight_norm': weight_norm,\n",
    "        'w': w_reg,\n",
    "        'b': b_reg\n",
    "    })\n",
    "    \n",
    "    print(f\"λ = {lambda_:<6} | Train Acc: {train_acc:5.1f}% | Test Acc: {test_acc:5.1f}% | ||w||: {weight_norm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Effect of regularization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Accuracy vs Lambda\n",
    "lambdas_plot = [r['lambda'] for r in results]\n",
    "train_accs = [r['train_acc'] for r in results]\n",
    "test_accs = [r['test_acc'] for r in results]\n",
    "\n",
    "axes[0].plot(lambdas_plot, train_accs, 'b-o', label='Training', markersize=8)\n",
    "axes[0].plot(lambdas_plot, test_accs, 'r-s', label='Test', markersize=8)\n",
    "axes[0].set_xscale('symlog', linthresh=0.01)\n",
    "axes[0].set_xlabel('Lambda (λ)')\n",
    "axes[0].set_ylabel('Accuracy (%)')\n",
    "axes[0].set_title('Accuracy vs Regularization Strength')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Weight Norm vs Lambda\n",
    "weight_norms = [r['weight_norm'] for r in results]\n",
    "axes[1].plot(lambdas_plot, weight_norms, 'g-^', markersize=8)\n",
    "axes[1].set_xscale('symlog', linthresh=0.01)\n",
    "axes[1].set_xlabel('Lambda (λ)')\n",
    "axes[1].set_ylabel('Weight Norm ||w||')\n",
    "axes[1].set_title('Weight Magnitude vs Regularization')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Weight comparison (λ=0 vs λ=1)\n",
    "x_pos = np.arange(len(selected_features))\n",
    "width = 0.35\n",
    "axes[2].barh(x_pos - width/2, np.abs(results[0]['w']), width, label='λ=0', color='blue', alpha=0.7)\n",
    "axes[2].barh(x_pos + width/2, np.abs(results[3]['w']), width, label='λ=1', color='orange', alpha=0.7)\n",
    "axes[2].set_yticks(x_pos)\n",
    "axes[2].set_yticklabels(selected_features)\n",
    "axes[2].set_xlabel('Absolute Weight')\n",
    "axes[2].set_title('Weight Comparison: No Reg vs L2')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best lambda\n",
    "best_result = max(results, key=lambda x: x['test_acc'])\n",
    "print(f\"\\nBest regularization: λ = {best_result['lambda']} with Test Accuracy = {best_result['test_acc']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 5: SageMaker Deployment\n",
    "\n",
    "## 5.1 Export Model for Deployment\n",
    "\n",
    "Save model parameters and preprocessing statistics for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model parameters\n",
    "import json\n",
    "\n",
    "model_data = {\n",
    "    'weights': w_learned.tolist(),\n",
    "    'bias': float(b_learned),\n",
    "    'feature_mean': feature_mean.tolist(),\n",
    "    'feature_std': feature_std.tolist(),\n",
    "    'features': selected_features,\n",
    "    'threshold': 0.5\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open('model_params.json', 'w') as f:\n",
    "    json.dump(model_data, f, indent=2)\n",
    "\n",
    "print(\"Model exported to 'model_params.json'\")\n",
    "print(f\"\\nModel contains:\")\n",
    "print(f\"  - {len(selected_features)} features\")\n",
    "print(f\"  - Weights: {len(model_data['weights'])} values\")\n",
    "print(f\"  - Bias: {model_data['bias']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Inference Function for Deployment\n",
    "\n",
    "Function that can be used in a SageMaker endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(input_data, model_params):\n",
    "    \"\"\"\n",
    "    Inference function for SageMaker deployment.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_data : dict or list\n",
    "        Patient features\n",
    "    model_params : dict\n",
    "        Model parameters from JSON\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with prediction and probability\n",
    "    \"\"\"\n",
    "    w = np.array(model_params['weights'])\n",
    "    b = model_params['bias']\n",
    "    mean = np.array(model_params['feature_mean'])\n",
    "    std = np.array(model_params['feature_std'])\n",
    "    threshold = model_params['threshold']\n",
    "    \n",
    "    X = np.array(input_data).reshape(1, -1)\n",
    "    X_norm = (X - mean) / std\n",
    "    \n",
    "    z = X_norm @ w + b\n",
    "    prob = 1 / (1 + np.exp(-z))\n",
    "    pred = int(prob >= threshold)\n",
    "    \n",
    "    return {\n",
    "        'prediction': pred,\n",
    "        'probability': float(prob[0]),\n",
    "        'risk_level': 'High' if pred == 1 else 'Low'\n",
    "    }\n",
    "\n",
    "# Test inference with a sample patient\n",
    "sample_patient = [55, 1, 3, 130, 250, 0, 1, 150, 0, 1.5]  # Example values\n",
    "\n",
    "result = inference(sample_patient, model_data)\n",
    "print(\"SAMPLE INFERENCE TEST\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Input: {dict(zip(selected_features, sample_patient))}\")\n",
    "print(f\"\\nPrediction: {result['prediction']} ({result['risk_level']} Risk)\")\n",
    "print(f\"Probability: {result['probability']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"COMPLETE PROJECT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "HEART DISEASE RISK PREDICTION - LOGISTIC REGRESSION\n",
    "\n",
    "Dataset: Kaggle Heart Disease (270 patients, 13 features)\n",
    "Algorithm: Logistic Regression from scratch (no sklearn)\n",
    "\n",
    "COMPLETED STEPS:\n",
    "----------------\n",
    "1. Data Preparation\n",
    "   - Loaded and explored dataset\n",
    "   - Binarized target (Presence=1, Absence=0)\n",
    "   - 70/30 stratified train/test split\n",
    "   - Z-score normalization\n",
    "\n",
    "2. Basic Logistic Regression\n",
    "   - Implemented sigmoid, cost, gradients\n",
    "   - Trained with gradient descent\n",
    "   - Test Accuracy: {test_metrics['accuracy']*100:.1f}%\n",
    "\n",
    "3. Decision Boundaries\n",
    "   - Visualized 3 feature pairs\n",
    "   - Demonstrated linear separability challenges\n",
    "\n",
    "4. L2 Regularization\n",
    "   - Tested λ ∈ [0, 0.01, 0.1, 1, 10]\n",
    "   - Best λ = {best_result['lambda']} (Test Acc: {best_result['test_acc']:.1f}%)\n",
    "\n",
    "5. SageMaker Deployment\n",
    "   - Exported model to JSON\n",
    "   - Created inference function\n",
    "   - Ready for cloud deployment\n",
    "\n",
    "LIBRARIES: NumPy, Pandas, Matplotlib (no sklearn for core training)\n",
    "\"\"\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
